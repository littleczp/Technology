# Transformer模型介绍

Transformer 是工业化、同质化的深度学习架构

* 设计背景：需要一种既能捕获全局上下文信息，又能极大地提升硬件（GPU/TPU）计算效率的数学模型
* 核心优势：相比于传统的 RNN 计算存在时序依赖，Transformer <mark style="color:$danger;">**解除了序列计算的强耦合，实现了高度的并行化**</mark>

> 同质化：指不同应用场景下的人工智能系统构建方式具有固定性；这使得**基础模型可以进行多种任务而不需要微调**（但也制造了单点故障风险）

Transformer 使用数十亿参数在数十亿条原始未标注数据上进行自监督学习

