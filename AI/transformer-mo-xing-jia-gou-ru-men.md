# Transformer模型架构入门

RNN：循环神经网络，一种用于处理序列数据的神经网络结构，它是一种连接模型，**通过循环节点网络来捕捉序列的动态**。其基本原理在于网络中存在循环连接，使得网络具有记忆能力，能够捕捉时间序列中的依赖关系。

{% hint style="info" %}
RNN的核心结构包括一个隐藏状态向量，该向量随着输入序列的每个时间步进行更新，从而在不同时间步传递信息。通过这种机制，RNN能够捕捉序列中的长短时依赖关系，并在自然语言处理、语音识别、时间序列预测等任务中展现出优异的性能
{% endhint %}

> 循环神经网络 (RNN) 和前馈神经网络 (Feedforward Neural Network) 是两种不同类型的神经网络
>
> 前馈神经网络是一种最简单的神经网络，其特点是信息从输入层流向输出层，不存在循环连接（独立性假设）。使得机器学习取得了很大的进展，适用于解决简单的回归问题或分类问题

<details>

<summary>RNN的局限性</summary>

循环神经网络(RNN)和LSTM一直将神经网络应用于NLP序列模型。然而，当面对长序列和大量参数时，循环神经网络因为**梯度消失、梯度爆炸和计算效率低**

</details>

