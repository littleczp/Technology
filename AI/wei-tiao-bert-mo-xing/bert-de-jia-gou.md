# BERT 的架构

BERT 将双向注意力机制引入 Transformer 模型中

## 编码器堆叠

